package main

import (
	"encoding/json"
	"fmt"
	"net/http"
	"net/url" // æ–°å¢ï¼šç”¨äºè§£æURLæå–ç«™ç‚¹Hostï¼ˆä¿®å¤å»é‡å…³é”®ï¼‰
	"strings"
	"sync"
	"time"

	"github.com/gin-gonic/gin"
	"cmas-cats-go/models"
)

// æ ¸å¿ƒé…ç½®ï¼ˆæ”¯æŒå¤šç«™ç‚¹ï¼Œå¯æŒ‰éœ€è°ƒæ•´ï¼‰
const (
	ListenPort     = ":8083"                          // C-SMAç›‘å¬ç«¯å£
	PollInterval   = 10 * time.Second                 // æ‹‰å–ç«™ç‚¹metricsé—´éš”
	// æœåŠ¡ç«™ç‚¹åˆ—è¡¨ï¼šé€—å·åˆ†éš”ï¼Œæ ¼å¼å¿…é¡»ä¸º "http://ç«™ç‚¹åœ°å€/metrics"
	ServiceSiteList = "http://localhost:8082/metrics,http://localhost:8085/metrics"
)

// å…¨å±€çŠ¶æ€ï¼šèšåˆåçš„metricsï¼ˆkey=ServiceIDï¼Œvalue=æ‰€æœ‰ç«™ç‚¹çš„å®ä¾‹ï¼‰
var (
	aggregatedMetrics = make(map[string][]models.ServiceInstanceInfo)
	metricsMutex      sync.RWMutex                                   // è¯»å†™é”ä¿è¯å¹¶å‘å®‰å…¨
)

func main() {
	// å¯åŠ¨æ ‡è¯†æ—¥å¿—
	fmt.Println("=====================================")
	fmt.Println("        C-SMA åº¦é‡æ”¶é›†æœåŠ¡å¯åŠ¨ä¸­...        ")
	fmt.Println("=====================================")

	// 1. è§£æå¹¶éªŒè¯æœåŠ¡ç«™ç‚¹åˆ—è¡¨
	sites := parseSiteList(ServiceSiteList)
	printSiteConfig(sites)

	// 2. åˆå§‹åŒ–Ginå¼•æ“
	r := gin.Default()

	// 3. æ³¨å†Œæ ¸å¿ƒæ¥å£
	r.GET("/sync", syncToCPSHandler)          // ä¾›C-PSæ‹‰å–èšåˆæ•°æ®
	r.GET("/current-metrics", getMetricsHandler) // è°ƒè¯•ï¼šæŸ¥çœ‹å½“å‰èšåˆæ•°æ®
	r.GET("/health", healthCheckHandler)      // å¥åº·æ£€æŸ¥

	// 4. å¯åŠ¨å¤šç«™ç‚¹æ‹‰å–ä»»åŠ¡ï¼ˆåå°åç¨‹ï¼Œä¸é˜»å¡æœåŠ¡ï¼‰
	go startMultiSitePolling(sites)

	// 5. å¯åŠ¨C-SMAæœåŠ¡
	fmt.Printf("\nâœ… C-SMA å¯åŠ¨æˆåŠŸï¼ç›‘å¬ç«¯å£ï¼š%s\n", ListenPort)
	if err := r.Run(ListenPort); err != nil {
		panic("âŒ C-SMA å¯åŠ¨å¤±è´¥ï¼š" + err.Error())
	}
}

// ------------------------------
// æ ¸å¿ƒ1ï¼šå¤šç«™ç‚¹metricsæ‹‰å–ï¼ˆå¸¦å¹¶å‘æ§åˆ¶ï¼‰
// ------------------------------

// startMultiSitePollingï¼šå®šæ—¶æ‹‰å–æ‰€æœ‰ç«™ç‚¹çš„metrics
func startMultiSitePolling(sites []string) {
	if len(sites) == 0 {
		fmt.Println("âš ï¸ æ— æœ‰æ•ˆæœåŠ¡ç«™ç‚¹ï¼Œåœæ­¢æ‹‰å–ä»»åŠ¡")
		return
	}

	// å®šæ—¶è§¦å‘å™¨ï¼šæ¯PollIntervalæ‰§è¡Œä¸€æ¬¡
	ticker := time.NewTicker(PollInterval)
	defer ticker.Stop()

	for range ticker.C {
		fmt.Printf("\n[%s] ğŸ“¥ å¼€å§‹æ‹‰å– %d ä¸ªæœåŠ¡ç«™ç‚¹çš„metrics...\n",
			time.Now().Format("2006-01-02 15:04:05"), len(sites))

		var wg sync.WaitGroup // ç­‰å¾…æ‰€æœ‰ç«™ç‚¹æ‹‰å–å®Œæˆ
		for _, siteURL := range sites {
			wg.Add(1)
			// å¹¶å‘æ‹‰å–ï¼ˆæå‡å¤šç«™ç‚¹åœºæ™¯æ•ˆç‡ï¼‰
			go func(url string) {
				defer wg.Done()
				// æ‹‰å–å•ä¸ªç«™ç‚¹çš„metrics
				siteMetrics, siteID, err := fetchSingleSiteMetrics(url)
				if err != nil {
					fmt.Printf("âŒ æ‹‰å–ç«™ç‚¹ [%s] å¤±è´¥ï¼š%v\n", url, err)
					return
				}
				// èšåˆæ•°æ®ï¼ˆå…ˆåˆ æ—§å®ä¾‹ï¼Œå†åŠ æ–°å®ä¾‹ï¼Œé¿å…é‡å¤ï¼‰
				metricsMutex.Lock()
				aggregateSiteMetrics(url, siteMetrics)
				metricsMutex.Unlock()

				fmt.Printf("âœ… æ‹‰å–ç«™ç‚¹ [%s] æˆåŠŸï¼š%d ä¸ªå®ä¾‹ï¼ˆç«™ç‚¹IDï¼š%sï¼‰\n",
					url, len(siteMetrics), siteID)
			}(siteURL)
		}

		wg.Wait() // ç­‰å¾…æ‰€æœ‰ç«™ç‚¹å¤„ç†å®Œæˆ
		// æ‰“å°èšåˆç»“æœæ‘˜è¦
		metricsMutex.RLock()
		serviceCount := len(aggregatedMetrics)
		totalInstances := countTotalInstances()
		metricsMutex.RUnlock()
		fmt.Printf("[%s] ğŸ“Š æ‰€æœ‰ç«™ç‚¹æ‹‰å–å®Œæˆ | èšåˆæœåŠ¡æ•°ï¼š%d | æ€»å®ä¾‹æ•°ï¼š%d\n",
			time.Now().Format("2006-01-02 15:04:05"), serviceCount, totalInstances)
	}
}

// fetchSingleSiteMetricsï¼šæ‹‰å–å•ä¸ªç«™ç‚¹çš„metricsï¼ˆå«å»¶è¿Ÿå­—æ®µï¼‰
func fetchSingleSiteMetrics(siteURL string) ([]models.ServiceInstanceInfo, string, error) {
	// å‘é€HTTP GETè¯·æ±‚åˆ°ç«™ç‚¹çš„/metricsæ¥å£
	resp, err := http.Get(siteURL)
	if err != nil {
		return nil, "", fmt.Errorf("HTTPè¯·æ±‚å¤±è´¥ï¼š%w", err)
	}
	defer resp.Body.Close()

	// æ£€æŸ¥å“åº”çŠ¶æ€ç 
	if resp.StatusCode != http.StatusOK {
		return nil, "", fmt.Errorf("çŠ¶æ€ç é”™è¯¯ï¼š%dï¼ˆæœŸæœ›200ï¼‰", resp.StatusCode)
	}

	// è§£æç«™ç‚¹è¿”å›çš„JSONæ•°æ®ï¼ˆåŒ…å«ç«™ç‚¹IDå’Œå®ä¾‹åˆ—è¡¨ï¼‰
	var siteResp struct {
		Success bool                     `json:"success"`
		SiteID  string                   `json:"site_id"`          // æœåŠ¡ç«™ç‚¹çš„å”¯ä¸€æ ‡è¯†ï¼ˆå¦‚site-1ï¼‰
		Metrics []models.ServiceInstanceInfo `json:"metrics"`         // å®ä¾‹åˆ—è¡¨ï¼ˆå«Delayå­—æ®µï¼‰
		Message string                   `json:"message"`
	}
	if err := json.NewDecoder(resp.Body).Decode(&siteResp); err != nil {
		return nil, "", fmt.Errorf("JSONè§£æå¤±è´¥ï¼š%w", err)
	}

	// æ£€æŸ¥ç«™ç‚¹ä¸šåŠ¡çŠ¶æ€
	if !siteResp.Success {
		return nil, "", fmt.Errorf("ç«™ç‚¹ä¸šåŠ¡é”™è¯¯ï¼š%s", siteResp.Message)
	}

	return siteResp.Metrics, siteResp.SiteID, nil
}

// ------------------------------
// æ ¸å¿ƒ2ï¼šå®ä¾‹èšåˆï¼ˆä¿®å¤å»é‡é€»è¾‘ï¼‰
// ------------------------------

// aggregateSiteMetricsï¼šèšåˆå•ä¸ªç«™ç‚¹çš„metricsï¼ˆå…ˆåˆ æ—§å®ä¾‹ï¼Œå†åŠ æ–°å®ä¾‹ï¼‰
func aggregateSiteMetrics(siteURL string, newMetrics []models.ServiceInstanceInfo) {
	// å…³é”®ä¿®å¤ï¼šè§£æç«™ç‚¹URLï¼Œæå–Hostï¼ˆå¦‚"localhost:8082"ï¼‰ä½œä¸ºå»é‡æ ‡è¯†
	parsedURL, err := url.Parse(siteURL)
	if err != nil {
		fmt.Printf("âš ï¸ è§£æç«™ç‚¹URL [%s] å¤±è´¥ï¼š%vï¼Œè·³è¿‡æ—§å®ä¾‹åˆ é™¤\n", siteURL, err)
		return
	}
	siteKey := parsedURL.Host // æ­£ç¡®çš„ç«™ç‚¹æ ‡è¯†ï¼ˆä¸å«http://ï¼Œä¸CSCI_IDæ ¼å¼åŒ¹é…ï¼‰

	// 1. åˆ é™¤è¯¥ç«™ç‚¹çš„æ‰€æœ‰æ—§å®ä¾‹ï¼ˆé¿å…é‡å¤èšåˆï¼‰
	for serviceID, oldInstances := range aggregatedMetrics {
		var retainedInstances []models.ServiceInstanceInfo
		for _, inst := range oldInstances {
			// é€šè¿‡CSCI_IDæ˜¯å¦åŒ…å«siteKeyï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºå½“å‰ç«™ç‚¹çš„å®ä¾‹
			if !strings.Contains(inst.CSCI_ID, siteKey) {
				retainedInstances = append(retainedInstances, inst)
			}
		}
		aggregatedMetrics[serviceID] = retainedInstances
	}

	// 2. è¿½åŠ è¯¥ç«™ç‚¹çš„æ–°å®ä¾‹ï¼ˆæ­¤æ—¶æ— é‡å¤ï¼‰
	for _, newInst := range newMetrics {
		serviceID := newInst.ServiceID
		aggregatedMetrics[serviceID] = append(aggregatedMetrics[serviceID], newInst)
	}
}

// ------------------------------
// è¾…åŠ©å‡½æ•°
// ------------------------------

// parseSiteListï¼šè§£ææœåŠ¡ç«™ç‚¹åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”â†’åˆ‡ç‰‡ï¼‰
func parseSiteList(listStr string) []string {
	var validSites []string
	for _, site := range strings.Split(listStr, ",") {
		trimmedSite := strings.TrimSpace(site)
		// éªŒè¯ï¼šéç©ºä¸”ä»¥"/metrics"ç»“å°¾ï¼ŒåŒæ—¶èƒ½è§£æä¸ºåˆæ³•URL
		if trimmedSite != "" && strings.HasSuffix(trimmedSite, "/metrics") {
			if _, err := url.Parse(trimmedSite); err == nil {
				validSites = append(validSites, trimmedSite)
			} else {
				fmt.Printf("âš ï¸ æ— æ•ˆç«™ç‚¹URLï¼š%sï¼ˆè§£æå¤±è´¥ï¼Œè·³è¿‡ï¼‰\n", trimmedSite)
			}
		}
	}
	return validSites
}

// printSiteConfigï¼šæ‰“å°ç«™ç‚¹é…ç½®ï¼ˆå¯åŠ¨æ—¶å±•ç¤ºï¼‰
func printSiteConfig(sites []string) {
	if len(sites) == 0 {
		fmt.Println("âš ï¸ æœªé…ç½®ä»»ä½•æœ‰æ•ˆæœåŠ¡ç«™ç‚¹ï¼")
		return
	}
	fmt.Printf("âœ… å·²é…ç½® %d ä¸ªæœåŠ¡ç«™ç‚¹ï¼Œæ‹‰å–é—´éš”ï¼š%v\n", len(sites), PollInterval)
	for i, site := range sites {
		// è§£æç«™ç‚¹Hostï¼Œä¾¿äºå±•ç¤º
		parsedURL, _ := url.Parse(site)
		fmt.Printf("   %d. %sï¼ˆHostï¼š%sï¼‰\n", i+1, site, parsedURL.Host)
	}
}

// countTotalInstancesï¼šç»Ÿè®¡æ‰€æœ‰å®ä¾‹æ€»æ•°
func countTotalInstances() int {
	total := 0
	for _, instances := range aggregatedMetrics {
		total += len(instances)
	}
	return total
}

// ------------------------------
// APIæ¥å£å®ç°ï¼ˆä¾›C-PSå’Œè°ƒè¯•ï¼‰
// ------------------------------

// syncToCPSHandlerï¼šå‘C-PSæä¾›èšåˆåçš„metricsï¼ˆå«å»¶è¿Ÿç»Ÿè®¡ï¼‰
func syncToCPSHandler(c *gin.Context) {
	metricsMutex.RLock()
	defer metricsMutex.RUnlock()

	// æ„é€ C-PSéœ€è¦çš„æ ¼å¼ï¼šæŒ‰ServiceIDåˆ†ç»„ï¼ŒåŒ…å«å®ä¾‹å’Œç»Ÿè®¡ä¿¡æ¯
	var syncData []struct {
		ServiceID string                     `json:"service_id"`
		Instances []models.ServiceInstanceInfo `json:"instances"` // æ‰€æœ‰å®ä¾‹ï¼ˆå«Delayï¼‰
		TotalGas  int                        `json:"total_gas"`  // è¯¥æœåŠ¡æ€»å®ä¾‹æ•°
		MinDelay  int                        `json:"min_delay"`  // æœ€å°å»¶è¿Ÿï¼ˆè¾…åŠ©C-PSå†³ç­–ï¼‰
		MaxDelay  int                        `json:"max_delay"`  // æœ€å¤§å»¶è¿Ÿ
	}

	for serviceID, instances := range aggregatedMetrics {
		// è®¡ç®—è¯¥æœåŠ¡çš„ç»Ÿè®¡ä¿¡æ¯
		totalGas := 0
		minDelay := 1 << 30 // åˆå§‹åŒ–ä¸ºæå¤§å€¼
		maxDelay := 0
		for _, inst := range instances {
			totalGas += inst.Gas
			if inst.Delay < minDelay {
				minDelay = inst.Delay
			}
			if inst.Delay > maxDelay {
				maxDelay = inst.Delay
			}
		}
		// å¤„ç†æ— å®ä¾‹çš„æç«¯æƒ…å†µ
		if minDelay == 1<<30 {
			minDelay = 0
		}

		syncData = append(syncData, struct {
			ServiceID string                     `json:"service_id"`
			Instances []models.ServiceInstanceInfo `json:"instances"`
			TotalGas  int                        `json:"total_gas"`
			MinDelay  int                        `json:"min_delay"`
			MaxDelay  int                        `json:"max_delay"`
		}{
			ServiceID: serviceID,
			Instances: instances,
			TotalGas:  totalGas,
			MinDelay:  minDelay,
			MaxDelay:  maxDelay,
		})
	}

	// è¿”å›åŒæ­¥ç»“æœï¼ˆå¸¦æ—¶é—´æˆ³å’Œç«™ç‚¹æ•°ï¼‰
	c.JSON(http.StatusOK, gin.H{
		"success":     true,
		"sync_time":   time.Now().Format("2006-01-02 15:04:05"),
		"service_num": len(syncData),
		"site_num":    len(parseSiteList(ServiceSiteList)),
		"data":        syncData,
	})
}

// getMetricsHandlerï¼šè°ƒè¯•æ¥å£ï¼ŒæŸ¥çœ‹å®Œæ•´èšåˆæ•°æ®
func getMetricsHandler(c *gin.Context) {
	metricsMutex.RLock()
	defer metricsMutex.RUnlock()

	c.JSON(http.StatusOK, gin.H{
		"success":          true,
		"last_update_time": time.Now().Format("2006-01-02 15:04:05"),
		"monitored_sites":  len(parseSiteList(ServiceSiteList)),
		"service_count":    len(aggregatedMetrics),
		"total_instances":  countTotalInstances(),
		"aggregated_data":  aggregatedMetrics, // å®Œæ•´å®ä¾‹æ•°æ®ï¼ˆå«Delayï¼‰
	})
}

// healthCheckHandlerï¼šå¥åº·æ£€æŸ¥æ¥å£ï¼ˆä¾›ç›‘æ§ç³»ç»Ÿï¼‰
func healthCheckHandler(c *gin.Context) {
	sites := parseSiteList(ServiceSiteList)
	status := "healthy"
	if len(sites) == 0 {
		status = "degraded" // æ— ç«™ç‚¹é…ç½®ï¼Œæ ‡è®°ä¸ºé™çº§
	}

	c.JSON(http.StatusOK, gin.H{
		"success":         true,
		"status":          status,
		"service":         "c-sma",
		"time":            time.Now().Format("2006-01-02 15:04:05"),
		"monitored_sites": len(sites),
	})
}
